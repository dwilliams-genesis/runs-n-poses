{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb7a649-5377-4784-b7b0-632871b9d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import rdkit\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc597000-096f-462a-b9b4-93cf63b0e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_af3_input(system_id, data, json_dir):\n",
    "    system_dict = dict()\n",
    "    system_dict[\"name\"] = system_id\n",
    "    system_dict[\"dialect\"] = \"alphafold3\"\n",
    "    system_dict[\"version\"] = 1\n",
    "    system_dict['modelSeeds'] = [random.randint(0, 2**32 - 1) for _ in range(5)]\n",
    "    sequences_list = list()\n",
    "    used_ids = set()\n",
    "    chain_ids = [c for c in string.ascii_uppercase]\n",
    "    protein_data = data[\"sequences\"]\n",
    "\n",
    "    for idx, (chain, seq) in enumerate(protein_data.items()):\n",
    "        protein_chain = dict()\n",
    "        protein_chain[\"protein\"] = dict()\n",
    "        protein_chain[\"protein\"][\"id\"] = chain_ids[idx]\n",
    "        protein_chain[\"protein\"][\"sequence\"] = seq\n",
    "        sequences_list.append(protein_chain)\n",
    "        used_ids.add(chain_ids[idx])\n",
    "\n",
    "    ligand_ids = [c for c in string.ascii_uppercase if c not in used_ids]\n",
    "\n",
    "    ligand_data = data[\"smiles\"]\n",
    "    ccd_data = data[\"ccd_codes\"]\n",
    "    \n",
    "    for idx, (smiles, ccd_code) in enumerate(zip(ligand_data, ccd_data)):\n",
    "        ligand_chain = dict()\n",
    "        ligand_chain[\"ligand\"] = dict()\n",
    "        ligand_chain[\"ligand\"][\"id\"] = ligand_ids[idx]\n",
    "        ligand_chain[\"ligand\"][\"smiles\"] = smiles\n",
    "        sequences_list.append(ligand_chain)\n",
    "\n",
    "    system_dict[\"sequences\"] = sequences_list\n",
    "    \n",
    "    output_json_path = os.path.join(json_dir, f\"{system_id}.json\")\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(system_dict, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5e0fef-133e-47b0-a467-ae4144f84641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_chai_input(system_id, data, fasta_dir):\n",
    "    lines = []\n",
    "    protein_data = data[\"sequences\"]\n",
    "    chain_ids = [c for c in string.ascii_uppercase]\n",
    "    used_ids = set()\n",
    "\n",
    "    for idx, (chain, seq) in enumerate(protein_data.items()):\n",
    "        lines.append(f\">protein|name={chain_ids[idx]}\")\n",
    "        lines.append(seq)\n",
    "        used_ids.add(chain_ids[idx])\n",
    "\n",
    "    ligand_data = data[\"smiles\"]\n",
    "    ccd_data = data[\"ccd_codes\"]\n",
    "    \n",
    "    ligand_ids = [c for c in string.ascii_uppercase if c not in used_ids]\n",
    "    \n",
    "    for idx, (smiles, ccd_code) in enumerate(zip(ligand_data, ccd_data)):\n",
    "        lines.append(f\">ligand|name={ligand_ids[idx]}\")\n",
    "        lines.append(smiles)\n",
    "    \n",
    "    fasta_string = \"\\n\".join(lines) + \"\\n\"\n",
    "\n",
    "    output_fasta_path = os.path.join(fasta_dir, f\"{system_id}.fasta\")\n",
    "    with open(output_fasta_path, 'w') as f:\n",
    "        f.write(fasta_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80c4dee-5f9f-418a-8530-e265c359de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_protenix_input(system_id, data, json_dir, msa_dir):\n",
    "    system_dict = dict()\n",
    "    system_dict[\"name\"] = system_id\n",
    "    sequences_list = list()\n",
    "\n",
    "    protein_data = data[\"sequences\"]\n",
    "    chain_ids = [c for c in string.ascii_uppercase]\n",
    "\n",
    "    for idx, (chain, seq) in enumerate(protein_data.items()):\n",
    "        protein_chain = dict()\n",
    "        chain_id = chain_ids[idx]\n",
    "        protein_chain[\"proteinChain\"] = dict()\n",
    "        protein_chain[\"proteinChain\"][\"count\"] = 1\n",
    "        protein_chain[\"proteinChain\"][\"sequence\"] = seq\n",
    "        protein_chain[\"proteinChain\"][\"msa\"] = dict()\n",
    "        protein_chain[\"proteinChain\"][\"msa\"][\"precomputed_msa_dir\"] = os.path.join(msa_dir, system_id.lower(), chain_id)\n",
    "        protein_chain[\"proteinChain\"][\"msa\"][\"pairing_db\"] = \"uniprot\"\n",
    "        sequences_list.append(protein_chain)\n",
    "\n",
    "    ligand_data = data[\"smiles\"]\n",
    "    for idx, smiles in enumerate(ligand_data):\n",
    "        ligand_chain = dict()\n",
    "        ligand_chain[\"ligand\"] = dict()\n",
    "        ligand_chain[\"ligand\"][\"ligand\"] = smiles\n",
    "        ligand_chain[\"ligand\"][\"count\"] = 1\n",
    "        sequences_list.append(ligand_chain)\n",
    "\n",
    "    system_dict[\"sequences\"] = sequences_list\n",
    "    system_list = [system_dict]\n",
    "    \n",
    "    output_json_path = os.path.join(json_dir, f\"{system_id}.json\")\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(system_list, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4638c66-ac43-4b57-af1c-4ddebfa178e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_boltz_input(system_id, data, yaml_dir, msa_dir):\n",
    "    query_sequences = {}\n",
    "    msa_files = {}\n",
    "    n_protein_chains = 0\n",
    "    \n",
    "    for sequence_id, sequence in data['sequences'].items():\n",
    "        chain = string.ascii_uppercase[n_protein_chains]\n",
    "\n",
    "        if sequence in query_sequences:\n",
    "            query_sequences[sequence].append(chain)\n",
    "        else:\n",
    "            query_sequences[sequence] = [chain]\n",
    "\n",
    "        csv_filename = f'{msa_dir}/{system_id.lower()}/{sequence_id}.csv'\n",
    "\n",
    "        if os.path.isfile(csv_filename):\n",
    "            msa_files[sequence] = os.path.abspath(csv_filename)\n",
    "\n",
    "        n_protein_chains += 1\n",
    "\n",
    "    query_ligands = {}\n",
    "\n",
    "    for i, smiles in enumerate(data['smiles']):\n",
    "        chain = string.ascii_uppercase[n_protein_chains + i]\n",
    "\n",
    "        if smiles in query_ligands:\n",
    "            query_ligands[smiles].append(chain)\n",
    "        else:\n",
    "            query_ligands[smiles] = [chain]\n",
    "\n",
    "    config = {'sequences': []}\n",
    "\n",
    "    for sequence, chains in query_sequences.items():\n",
    "        config['sequences'].append({'protein': {'id': sorted(chains), 'sequence': sequence, 'msa': msa_files[sequence]}})\n",
    "\n",
    "    for smiles, chains in query_ligands.items():\n",
    "        config['sequences'].append({'ligand': {'id': sorted(chains), 'smiles': smiles}})\n",
    "\n",
    "    output_path = os.path.join(yaml_dir, f\"{system_id}.yaml\")\n",
    "    with open(output_path, 'w') as w:\n",
    "        yaml.dump(config, w, sort_keys=False, width=5000, default_flow_style=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f541ecd-ea0c-45dd-8274-28e6b2dbb4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json = \"data/inputs.json\"\n",
    "msa_dir = \"data/msa_files\"\n",
    "\n",
    "with open(input_json, 'r') as f:\n",
    "    input_data = json.load(f)\n",
    "\n",
    "af3_input_dir = \"examples/inputs/af3\"\n",
    "chai_input_dir = \"examples/inputs/chai\"\n",
    "protenix_input_dir = \"examples/inputs/protenix\"\n",
    "boltz_input_dir = \"examples/inputs/boltz\"\n",
    "example_msa_dir = \"examples/inputs/msa_files\"\n",
    "\n",
    "os.makedirs(af3_input_dir, exist_ok=True)\n",
    "os.makedirs(chai_input_dir, exist_ok=True)\n",
    "os.makedirs(protenix_input_dir, exist_ok=True)\n",
    "os.makedirs(boltz_input_dir, exist_ok=True)\n",
    "\n",
    "example_id = \"8c3u__1__1.A__1.C\"\n",
    "for system_id, data in input_data.items():\n",
    "    if system_id == example_id:\n",
    "        prepare_af3_input(system_id, data, af3_input_dir)\n",
    "        prepare_chai_input(system_id, data, chai_input_dir)\n",
    "        prepare_protenix_input(system_id, data, protenix_input_dir, example_msa_dir)\n",
    "        prepare_boltz_input(system_id, data, boltz_input_dir, example_msa_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e76ce5c-31b2-43ed-9703-8e8f027a2696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mambaforge-ost_env]",
   "language": "python",
   "name": "conda-env-mambaforge-ost_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
